"""
La stratégie à suivre: faire des mise à jour à deux sites,
le coté "arrière" est multiplié par la racinne quatrième de la somme des carré des valeurs singulière, 
le coté "avant" est contracté avec les valeurs singulière et divisé par la quatrième racine des la somme des carrées des valeur singulière.
Les tenseurs environnements doivent être normalisé de sorte à évité l'apparition de la norme total dans la mise à jours.

"""
class Env_holder:
    """
    class to hold the MPTs that makes up the enviroments of a 1d-sweeping tensor algorithm.
    Takes care of the fiddling with the site index. The environment generated by the tensors at site i can be accessed by using [j,i] where j is the jth environment List
    """
    def __init__(self,env):
        self.env = env

    def __getitem__(self,i:tuple[int,int]):
        i,j = i
        return self.env[i][j+1]

    def __setitem__(self,i:tuple[int,int],value):
        i,j = i
        self.env[i][j+1] = value

from operator import index
from quimb import norm
import quimb.tensor as qtn
from typing import List
import numpy as np

def Nroots_prediction(norms:np.array):
    """Compute the second order approximation to the Nth root of the product of the supplied list. Nth roots rapidly converge to 1 as N increase with finite precision arithmetic. This approximation should be more accurate than the direct computation with double precision floats"""
    #could be computed exactly using logarithms and exponentials... but it wouldn't save us from doing it repeatedly, and this is cheaper.
    av = np.mean(norms)
    deltas = norms - av
    N = len(norms)
    x = -np.sum(deltas**2)
    x = x/(av*N*(N-1))
    return av + x

def guess_tensor_norm(target_norms,norm2,oc,direction):
    """guess the N root of the norm of the MPO from the norms of the individual tensors and the norm of the update. The value converge exponentially fast in the network optimization procedure."""
    target_norms[oc] = norm2
    target_norms[oc+direction] = norm2
    target_norm_root = Nroots_prediction(target_norms) ## doit être m-a-j avec les tenseur de target. L'algo suppose que target_norm_root^L est la norm du réseau cible.
    a = 1
    b = (norm2 < target_norm_root)*(np.abs(np.log(norm2/target_norm_root)))#when norm2 is small, it pays to reduce the norm faster.
    target_norm_root = ((a*target_norm_root + b*norm2)/(a+b)) ##injecting the average to speedup norm distribution convergence, not using just it to reduce overshooting oscillation
    target_norms[oc] = target_norm_root
    target_norms[oc+direction] = target_norm_root
    norm = np.sqrt(target_norm_root)
    return norm


def sum_sweep(MPOs:List[qtn.MatrixProductOperator],target:qtn.MatrixProductOperator,envs,direction,tol,oc,target_norms,max_bond):
    Env = Env_holder(envs)
    starting_oc = oc
    target.calc_current_orthog_center
    L = target.L
    direction = 1
    if oc == L-1:
        direction = -1
    count = 0
    while True:
        indexshift = (direction - 1)//2
        Tens = (Env[0,oc+indexshift-1]|MPOs[0][oc + indexshift ]|MPOs[0][oc+indexshift+1]|Env[0,oc+indexshift+2]).contract()
        for i,t in enumerate(MPOs[1:]):
            Tens += (Env[i+1,oc+indexshift-1]|MPOs[i+1][oc + indexshift]|MPOs[i+1][oc+indexshift+1]|Env[i+1,oc+indexshift+2]).contract()
        n = len(MPOs[0][oc+direction].inds)-1
        if direction == 1:
            right_inds,left_inds = Tens.inds[-n:],None
        else:
            right_inds,left_inds = None,Tens.inds[:n]
        U,d,V = qtn.tensor_split(Tens,right_inds=right_inds,left_inds=left_inds,absorb=None,cutoff=tol,max_bond=max_bond)
        if direction == 1:
            N = U
        else:
            N = V
        norm2 = np.sqrt(d@d)
        norm = guess_tensor_norm(target_norms,norm2,oc,direction) 
        N *= norm
        N.drop_tags()
        for tag in target[oc].tags:
            N.add_tag(tag)
        target[oc] = N## besoin d'adaptation pour gérer la norme
        for i,t in enumerate(MPOs):## besoin d'adaptation pour gérer la norme
            Env[i,oc] = (target[oc].H|t[oc]|Env[i,oc-direction]).contract()/norm**2
            assert(len(Env[i,oc].inds) == 2)
            
        oc += direction
        direction  = direction - 2*(oc == (L-1) or oc==0)*direction

        if oc == starting_oc:
            tags = target[oc].tags
            tmp = (Env[0,oc-1]| MPOs[0][oc]|Env[0,oc+1]).contract()
            for i,t in enumerate(MPOs[1:]):
                tmp += (Env[i+1,oc-1]|t[oc]|Env[i+1,oc+1]).contract()
            tmp.drop_tags()
            for tag in tags:
                tmp.add_tag(tag)
            target[oc] = tmp
            break
        count += 1
    out = (target[oc]@target[oc].H)
    return out


def mpompo_env_prep(mpoA,mpoB,target_norm,oc):
    L = mpoA.L
    outleft = []
    outleft.append(qtn.Tensor(data = 1,inds = ()))
    for i in range(oc): 
        outleft.append((outleft[-1]|mpoA[i].H|mpoB[i]).contract()/target_norm)
    outright = []
    outright.append(qtn.Tensor(data = 1,inds = ()))
    for i in range(L-1,oc,-1):
        outright.append((outright[-1]|mpoA[i].H|mpoB[i]).contract()/target_norm)
    outright.reverse()
    return outleft+[qtn.Tensor()]+outright


def MPO_compressing_sum(MPOs:List[qtn.MatrixProductOperator],tol:float,crit:float, max_bond=None):
    #check free indices are compatible across all input MPS
    mpo0 = MPOs[0]
    N = mpo0.L
    tens_arr = [np.random.rand(4,4,x.ind_size(mpo0.upper_ind_id.format(c)),x.ind_size(mpo0.lower_ind_id.format(c))) for c,x in enumerate(mpo0)]
    tens_arr[0] = tens_arr[0][0,:,:,:]
    tens_arr[-1] = tens_arr[-1][:,0,:,:]
    mpsi_n = 0
    for mpsi in MPOs[1:]:
        assert(mpsi.L == N)
        c = 0
        for x in mpsi:
            sup = x.ind_size(mpsi.upper_ind_id.format(c))
            sdn = x.ind_size(mpsi.lower_ind_id.format(c))
            assert(sup == tens_arr[c].shape[-2])
            assert(sdn == tens_arr[c].shape[-1])
            c += 1
        mpsi.upper_ind_id = mpo0.upper_ind_id
        mpsi.lower_ind_id = mpo0.lower_ind_id
        mpsi_n += 1
    out = qtn.MatrixProductOperator(tens_arr,shape='lrud',upper_ind_id=mpo0.upper_ind_id, lower_ind_id=mpo0.lower_ind_id,site_tag_id='out{}')
    oc = out.calc_current_orthog_center()
    if oc[0] == oc[1]:
        oc = oc[0]
    else:
        oc = out.L-1
    norms = [x@x.H for x in out]
    tgt_norm = np.mean(norms)
    envs = [mpompo_env_prep(out,m,tgt_norm,oc) for m in MPOs]
    cost = 1.0e18
    new_cost = 0
    direction = 1
    iter_count = 0
    while True:
        new_cost = sum_sweep(MPOs,out,envs,direction,tol,oc,norms,max_bond=max_bond)
        if abs(2*(new_cost-cost)/(new_cost+cost)) < crit:
            break
        cost = new_cost
        iter_count += 1
        if (iter_count > 1000):
            print("Compressing sum failed to converge")
            break
    print("iterations: ", iter_count)
    return out


if __name__=="__main__":
    pass